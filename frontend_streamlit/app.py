import streamlit as st
import requests
import os

st.set_page_config(page_title="DocuFlow Chat", layout="wide")

# 1. Konfiguracja URL
# WewnÄ…trz sieci Docker Twoje API Gateway jest dostÄ™pne pod nazwÄ… serwisu i portem wewnÄ™trznym
GATEWAY_URL = os.getenv("API_GATEWAY_URL", "http://docuflow_api_gateway:8001")

# ZMIANA 1: Endpoint to /query, a nie /chat (zgodnie z Twoim kodem FastAPI)
CHAT_ENDPOINT = f"{GATEWAY_URL}/query"

st.title("ðŸ“„ DocuFlow Q&A")

if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("Zadaj pytanie do dokumentÃ³w..."):
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("assistant"):
        with st.spinner("Szukam odpowiedzi w dokumentach..."):
            try:
                # ZMIANA 2: Dostosowanie payloadu do modelu QueryRequest w FastAPI
                # class QueryRequest(BaseModel):
                #     question: str  <--- To jest wymagane pole
                #     categories_to_search: list[str] | None = None
                
                payload = {
                    "question": prompt,
                    "categories_to_search": None # MoÅ¼esz tu dodaÄ‡ logikÄ™ wyboru kategorii w UI
                }
                
                response = requests.post(CHAT_ENDPOINT, json=payload, timeout=60)
                
                if response.status_code == 200:
                    # ZakÅ‚adam, Å¼e LLM Core zwraca JSON, np. {"answer": "Tekst"} 
                    # lub API Gateway przekazuje odpowiedÅº 1:1.
                    # SprawdÅº co dokÅ‚adnie zwraca TwÃ³j LLM Core.
                    data = response.json()
                    
                    # SprÃ³buj pobraÄ‡ odpowiedÅº z rÃ³Å¼nych typowych kluczy
                    ai_text = data.get("answer") or data.get("response") or data.get("result") or str(data)
                    
                    st.markdown(ai_text)
                    st.session_state.messages.append({"role": "assistant", "content": ai_text})
                else:
                    st.error(f"BÅ‚Ä…d API ({response.status_code}): {response.text}")
            
            except requests.exceptions.ConnectionError:
                st.error(f"Nie moÅ¼na poÅ‚Ä…czyÄ‡ siÄ™ z: {CHAT_ENDPOINT}. SprawdÅº czy API Gateway dziaÅ‚a.")
            except Exception as e:
                st.error(f"WystÄ…piÅ‚ bÅ‚Ä…d: {e}")